{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"K-Means Clustering -- Criteria","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CMTPAf7MCEe-"},"source":["This notebook performs a baseline K-Means Clustering pipeline on the Hessel artwork collection. \r\n","\r\n","The general idea of K-means is to find datapoints that are close together in a vector space and put them into a cluster. There will be a final of K clusters. The open question is the conversion of datapoint into numerical vectors. This relates to the meaning of distance in the vector space, which is used by K-means for clustering. \r\n","\r\n","Open questions for using K-means:\r\n","1.   How should we weight different columns? Currently every column is normalized. Can incorporate human knowledge related to artworks inot weighting. \r\n","2.   How many clusters should we use? Can explore optimization or statistical anaylses on various with the number of clusters of parameter to find the best value for k. \r\n","3. The interpretation of relation with each cluster?\r\n","4. How should we convert text into numeric embeddings as the input to the K-means model? Some candidates are one-hot encoding, word2vect, and label encoder (the current method). "]},{"cell_type":"markdown","metadata":{"id":"LFXTti-OG9r_"},"source":["## Import Data and Libraries "]},{"cell_type":"code","metadata":{"id":"auQhqsWlghmi"},"source":["from google.colab import auth\r\n","auth.authenticate_user()\r\n","import gspread\r\n","from oauth2client.client import GoogleCredentials\r\n","import numpy as np\r\n","import pandas as pd\r\n","\r\n","# open data from google sheet\r\n","gc = gspread.authorize(GoogleCredentials.get_application_default())\r\n","wb = gc.open_by_key(\"1Fr1y3l9pDmSZ1cJWrzVMgKjWpgWy03yclnN7p3_4slw\")\r\n","worksheet = wb.worksheet(\"Object_Data\")\r\n","rows = worksheet.get_all_values()\r\n","# print(rows[0])\r\n","worksheet_type = wb.worksheet(\"Schema\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fkt-L-VAg66g"},"source":["# open sheet as panda dataframe \r\n","df_type = pd.DataFrame(worksheet_type.get_all_records())\r\n","df = pd.DataFrame(worksheet.get_all_records())\r\n","\r\n","drop_cols = [\"Medium\",\r\n","             \"included_in_exhibitions\"]\r\n","\r\n","# drop Medium for now until its parsed \r\n","df = df.drop(columns=drop_cols, axis=1)\r\n","df_type = df_type.drop(columns=[\"Medium\", \"included_in_exhibitions\"], axis=1)\r\n","\r\n","# df.head()\r\n","# for i in df.columns: \r\n","#   print(df[i].dtypes, i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Mck7z-63axW"},"source":["df.replace('', np.nan, inplace=True) \r\n","df.fillna(\"0\",inplace=True)\r\n","# df.head()\r\n","# df.loc[df['object_id'] == 3831]\r\n","# df.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_rAUtd0J4P5c"},"source":["## Uncomment to use word to vect \r\n","# import tensorflow_hub as hub\r\n","# # Generating Vectors using the Universal Sentence Encoder => convert words into vectors \r\n","# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\r\n","# embeddings = embed([\r\n","#     \"The quick brown fox jumps over the lazy dog.\",\r\n","#     \"I am a sentence for which I would like to get its embedding\"])\r\n","# print(embeddings)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37jxNUgQGztX"},"source":["## Data Processing"]},{"cell_type":"code","metadata":{"id":"6dupGso-AeVo","colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"status":"error","timestamp":1612639576971,"user_tz":300,"elapsed":16285,"user":{"displayName":"Henry Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOZGhl1SkcshsRm-a8PDhVvWgak9vy7R7uzW45-w=s64","userId":"11261548985421580714"}},"outputId":"d95ca946-b92a-438c-df2b-cf820e3184a5"},"source":["# Preprocess the data into format that will be ready as input for K-means model\r\n","label_encoders = {} \r\n","str_cols = []\r\n","from sklearn import preprocessing # find the columns that are not int or float. They will be converted into vector embeddings. \r\n","\r\n","for typ in df_type.columns:\r\n","  print(typ)\r\n","  if df_type.iloc[0][typ] == \"(lat, lon)\":\r\n","    # Convert Goelocation to one numeric value \r\n","    pass\r\n","  elif df_type.iloc[0][typ] == \"bool\":\r\n","    df[typ] = df[typ].apply(lambda x: 1 if x ==\"TRUE\" else 0)\r\n","\r\n","  elif df_type.iloc[0][typ] not in [\"int\", \"float\"]:\r\n","    print(df_type.iloc[0][typ])\r\n","    le = preprocessing.LabelEncoder()\r\n","    df[typ] = df[typ].astype(\"str\")\r\n","    le.fit(df[typ]) # entire column \r\n","    label_encoders[typ] = le\r\n","    df[typ] = le.transform(df[typ])\r\n","  else: \r\n","    # numerical values\r\n","    if df_type.iloc[0][typ] == \"width_mm\" or \"height_mm\":\r\n","      df[typ] = df[typ].astype('str').str.replace(',','')\r\n","    df[typ] = pd.to_numeric(df[typ])\r\n","\r\n","    ## uncomment to use word2vec\r\n","    # str_cols.append(typ)\r\n","    # df[typ] = df[typ].str.replace(\",\", '')\r\n","\r\n","    # #generate embeddings\r\n","    # embeddings = embed(df[typ])\r\n","\r\n","    # #create list from np arrays\r\n","    # use = np.array(embeddings).tolist()\r\n","\r\n","    # #add lists as dataframe column\r\n","    # df[typ + \"_vect\"] = use"],"execution_count":null,"outputs":[{"output_type":"stream","text":["r\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to parse string \"r\"","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-81e2e14f9b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"width_mm\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"height_mm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m## uncomment to use word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unable to parse string \"r\" at position 0"]}]},{"cell_type":"code","metadata":{"id":"NijvG6DtKe7y"},"source":["# Normalize dataframe to remove the scaling of units in different columns.\r\n","train_df = df.copy().drop(columns=[\"r\"], axis=1)\r\n","normalized_train_df=(train_df-train_df.min())/(train_df.max()-train_df.min())\r\n","train_df = df.drop(str_cols, axis=1)\r\n","normalized_train_df.dtypes\r\n","normalized_train_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJj7QK54hDzt"},"source":["import matplotlib.pyplot as plt\r\n","from sklearn.cluster import KMeans\r\n","\r\n","\r\n","# set all NaN values to 0\r\n","normalized_train_df = normalized_train_df.fillna(0)\r\n","normalized_train_np = normalized_train_df.to_numpy()\r\n","\r\n","# find the best k value following the silhouette method at https://medium.com/analytics-vidhya/how-to-determine-the-optimal-k-for-k-means-708505d204eb \r\n","from sklearn.metrics import silhouette_score\r\n","sil = []\r\n","kmax = 10\r\n","\r\n","# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\r\n","for k in range(2, kmax+1):\r\n","  kmeans = KMeans(n_clusters = k).fit(normalized_train_np)\r\n","  labels = kmeans.labels_\r\n","  sil.append(silhouette_score(normalized_train_np, labels, metric = 'euclidean'))\r\n","\r\n","plt.plot(range(2, kmax+1), sil )\r\n","# seems like k= 6, 25 are good k values "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2v-V5MzDCitL"},"source":["kmeans = KMeans(n_clusters=6).fit(normalized_train_np)\r\n","centroids = kmeans.cluster_centers_\r\n","# print(centroids)\r\n","\r\n","# statistical anaylsis on each cluster can start here "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q-D6lEF2Fjq6"},"source":["## Visualize Clustering (In progress).\r\n","See this [link](https://www.kaggle.com/minc33/visualizing-high-dimensional-clusters) for reference."]},{"cell_type":"code","metadata":{"id":"ndc69rOsUDNZ"},"source":["from sklearn.decomposition import PCA #Principal Component Analysis\r\n","from sklearn.manifold import TSNE #T-Distributed Stochastic Neighbor Embedding\r\n","import plotly as py\r\n","import plotly.graph_objs as go\r\n","from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\r\n","import plotly.offline as pyo \r\n","\r\n","X=[]\r\n","X = normalized_train_df\r\n","clusters = kmeans.predict(X)\r\n","X[\"Cluster\"] = clusters\r\n","plotX = X.copy()\r\n","\r\n","#PCA with three principal components\r\n","pca_3d = PCA(n_components=3)\r\n","\r\n","#And this DataFrame contains three principal components that will aid us\r\n","#in visualizing our clusters in 3-D\r\n","PCs_3d = pd.DataFrame(pca_3d.fit_transform(plotX.drop([\"Cluster\"], axis=1)))\r\n","PCs_3d.columns = [\"PC1_3d\", \"PC2_3d\", \"PC3_3d\"]\r\n","plotX = pd.concat([plotX, PCs_3d], axis=1, join='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmcWL41mQbFz"},"source":["cluster0 = plotX[plotX[\"Cluster\"] == 0]\r\n","cluster1 = plotX[plotX[\"Cluster\"] == 1]\r\n","cluster2 = plotX[plotX[\"Cluster\"] == 2]\r\n","cluster3 = plotX[plotX[\"Cluster\"] == 3]\r\n","cluster4 = plotX[plotX[\"Cluster\"] == 4]\r\n","cluster5 = plotX[plotX[\"Cluster\"] == 5]\r\n","\r\n","print(len(cluster0)) \r\n","print(len(cluster1)) \r\n","print(len(cluster2)) \r\n","print(len(cluster3)) \r\n","print(len(cluster4)) \r\n","print(len(cluster5)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecBLERXOcR5v"},"source":["#Instructions for building the 3-D plot\r\n","\r\n","#trace1 is for 'Cluster 0'\r\n","trace1 = go.Scatter3d(\r\n","                    x = cluster0[\"PC1_3d\"],\r\n","                    y = cluster0[\"PC2_3d\"],\r\n","                    z = cluster0[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 0\",\r\n","                    marker = dict(color = 'rgba(255, 0, 0, 0.8)'),\r\n","                    text = None)\r\n","\r\n","#trace2 is for 'Cluster 1'\r\n","trace2 = go.Scatter3d(\r\n","                    x = cluster1[\"PC1_3d\"],\r\n","                    y = cluster1[\"PC2_3d\"],\r\n","                    z = cluster1[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 1\",\r\n","                    marker = dict(color = 'rgba(0, 255, 0, 0.8)'),\r\n","                    text = None)\r\n","\r\n","#trace3 is for 'Cluster 2'\r\n","trace3 = go.Scatter3d(\r\n","                    x = cluster2[\"PC1_3d\"],\r\n","                    y = cluster2[\"PC2_3d\"],\r\n","                    z = cluster2[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 2\",\r\n","                    marker = dict(color = 'rgba(0, 0, 255, 0.8)'),\r\n","                    text = None)\r\n","\r\n","#trace4 is for 'Cluster 3'\r\n","trace4 = go.Scatter3d(\r\n","                    x = cluster3[\"PC1_3d\"],\r\n","                    y = cluster3[\"PC2_3d\"],\r\n","                    z = cluster3[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 3\",\r\n","                    marker = dict(color = 'rgba(0, 0, 0, 0.8)'),\r\n","                    text = None)\r\n","\r\n","#trace5 is for 'Cluster 4'\r\n","trace5 = go.Scatter3d(\r\n","                    x = cluster4[\"PC1_3d\"],\r\n","                    y = cluster4[\"PC2_3d\"],\r\n","                    z = cluster4[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 4\",\r\n","                    marker = dict(color = 'rgba(0, 255, 250, 0.8)'),\r\n","                    text = None)\r\n","\r\n","#trace6 is for 'Cluster 5'\r\n","trace6 = go.Scatter3d(\r\n","                    x = cluster5[\"PC1_3d\"],\r\n","                    y = cluster5[\"PC2_3d\"],\r\n","                    z = cluster5[\"PC3_3d\"],\r\n","                    mode = \"markers\",\r\n","                    name = \"Cluster 5\",\r\n","                    marker = dict(color = 'rgba(255, 255, 0, 0.8)'),\r\n","                    text = None)\r\n","\r\n","\r\n","data = [trace1, trace2, trace3, trace4, trace5, trace6]\r\n","\r\n","title = \"Visualizing Clusters in Three Dimensions Using PCA\"\r\n","\r\n","layout = dict(title = title,\r\n","              xaxis= dict(title= 'PC1',ticklen= 5,zeroline= False),\r\n","              yaxis= dict(title= 'PC2',ticklen= 5,zeroline= False)\r\n","             )\r\n","\r\n","fig = dict(data = data, layout = layout)\r\n","\r\n","iplot(fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WzbFNl82c30O"},"source":["## Further Exploration"]},{"cell_type":"code","metadata":{"id":"J7bsGLxGfZxL"},"source":["X = train_df.drop(columns=[\"r\"]) # categorial columns = [0, 1, 19]\r\n","X_type = df_type.drop(columns=[\"r\"])\r\n","\r\n","# find columns that are categorical \r\n","categorical = [i for i, x in enumerate(X_type.iloc[2] == \"categorical\") if x]\r\n","print(categorical)\r\n","\r\n","categorical_types =[]\r\n","for i in range(len(X.columns)):\r\n","  if i in categorical:\r\n","    categorical_types.append(X.columns[i])\r\n","print(categorical_types)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dTEwTfcc2-4"},"source":["# !pip install kmodes\r\n","# !pip install --upgrade kmodes\r\n","from kmodes.kprototypes import KPrototypes\r\n","\r\n","# note that the training data here is not normalized!\r\n","X = train_df.drop(columns=[\"r\"])\r\n","kproto = KPrototypes(n_clusters=6, init='Cao', verbose=2)\r\n","clusters = kproto.fit_predict( X, categorical=categorical)\r\n","\r\n","# Print cluster centroids of the trained model.\r\n","print(kproto.cluster_centroids_)\r\n","# Print training statistics\r\n","print(kproto.cost_)\r\n","print(kproto.n_iter_)\r\n","\r\n","\r\n","# Plot the results\r\n","# for i in set(kproto.labels_):\r\n","#     index = kproto.labels_ == i\r\n","#     plt.plot(X[index, 0], X[index, 1], 'o')\r\n","#     plt.suptitle('Data points categorized with category score', fontsize=18)\r\n","#     plt.xlabel('Category Score', fontsize=16)\r\n","#     plt.ylabel('Category Type', fontsize=16)\r\n","# plt.show()\r\n","# # Clustered result\r\n","# fig1, ax3 = plt.subplots()\r\n","# scatter = ax3.scatter(syms, clusters, c=clusters, s=50)\r\n","# ax3.set_xlabel('Data points')\r\n","# ax3.set_ylabel('Cluster')\r\n","# plt.colorbar(scatter)\r\n","# ax3.set_title('Data points classifed according to known centers')\r\n","# plt.show()\r\n","# result = zip(syms, kproto.labels_)\r\n","# sortedR = sorted(result, key=lambda x: x[1])\r\n","# print(sortedR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ZLtVCTcObYj"},"source":["Reference: \r\n","\r\n","1.  [Visualize High Dimensional Data](https://www.kaggle.com/minc33/isualizing-high-dimensional-clusters)\r\n","2.   List item\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"QZOapTNz6B6p"},"source":["clus = kproto.cluster_centroids_\r\n","n_cols = len(clus[0][0]) + len(clus[1][1])\r\n","k = 6 # number of clusters\r\n","clus_data = []\r\n","\r\n","for i in range(k):\r\n","  row = []\r\n","  num, cat = np.ndarray.tolist(clus[0][i]), np.ndarray.tolist(clus[1][i])\r\n","  for j in range(n_cols): \r\n","    if j in categorical: # categorical \r\n","      row.append(cat.pop(0))\r\n","    else:\r\n","      row.append(num.pop(0)) # numerical \r\n","  print(row)\r\n","  clus_data.append(row)\r\n","\r\n","\r\n","for i in range(6):\r\n","  print(clus[0][i], clus[1][i]) # numerical cols, categorical cols."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6fiMubg9CTc"},"source":[" # this is the center of eachof each cluster \r\n"," clus_df = pd.DataFrame(columns=X.columns, data=clus_data)\r\n"," clus_df.head(6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdPvRtMzKx3C"},"source":["### The Final Cluster Center"]},{"cell_type":"code","metadata":{"id":"ptuoDL2ZFNld"},"source":["# now convert categories back to \r\n","for typ in categorical_types:\r\n","  clus_df[typ]= label_encoders[typ].inverse_transform(  clus_df[typ].astype('int32'))\r\n","clus_df.head(6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pg0M-_mcKHBC"},"source":["### Insights: \r\n","The above are the center of each clusters, which in a sense is the average of each art piece within the cluster. Art pieces in the same cluster are close with each other, so they should share the similar features. The center is representative of the features shared (pattern) in each cluster. The details could be seen by examining the statistics of the (avg, stdev, etc) of each column for each cluster. \r\n","\r\n","We can see that the columns that are all zero are actually quite meaningless. The accession_year, creation_date, artist_name display are more charateristics of each cluster. More work needs to be done.\r\n","\r\n","\r\n","**Bottleneck:** The “Medium” column has multiple values inside. Each value has a stand alone meaning but combinations of values also make special meaning. ”included_in_exhibitions” also have multiple values if we use them as a feature. Currently, I omitted these two columns for simplicity. Also because of my limitation.\r\n","\r\n","Some approaches: \r\n","1) We can break these into multiple columns and perform one hot encoding, however if one value, say sculpture” has too low a frequency then the dummy column “sculpture” created for one-hot would become meaningless. \r\n","2) We can use word2vec to create vector embeddings of the values. This approach preserves semantics but requires more technicality. As word2vect has limitations on preserving semantics, whether the cluster center is a meaningful representative of the entire cluster is another question. I think this is the most promising yet challenging approach. \r\n","\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"3cNoYH28L2bh"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"McZLqsIozzt7","executionInfo":{"status":"ok","timestamp":1612639588542,"user_tz":300,"elapsed":382,"user":{"displayName":"Henry Chang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiOZGhl1SkcshsRm-a8PDhVvWgak9vy7R7uzW45-w=s64","userId":"11261548985421580714"}},"outputId":"8d7f8820-6b9f-4b6c-d9ea-0b8519546c9c"},"source":["df.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>r</th>\n","      <th>artist_name</th>\n","      <th>classification</th>\n","      <th>no_of_components</th>\n","      <th>accession_year</th>\n","      <th>age_when_acquired</th>\n","      <th>artist_living</th>\n","      <th>has_comments</th>\n","      <th>creation_date</th>\n","      <th>with_collector</th>\n","      <th>editioned</th>\n","      <th>addl_artist_info</th>\n","      <th>has_commentary</th>\n","      <th>has_location</th>\n","      <th>has_object_description</th>\n","      <th>has_installation_instructions</th>\n","      <th>width_mm</th>\n","      <th>height_mm</th>\n","      <th>num_exhibitions</th>\n","      <th>exhibition_location</th>\n","      <th>time_exhibited</th>\n","      <th>artist_birthplace_lat</th>\n","      <th>artist_birthplace_lon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665.0</td>\n","      <td>1665</td>\n","      <td>1665</td>\n","      <td>1665.0</td>\n","      <td>1665</td>\n","      <td>1665.0</td>\n","      <td>1665.000000</td>\n","      <td>1665.000000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>1620</td>\n","      <td>517</td>\n","      <td>36</td>\n","      <td>35</td>\n","      <td>32</td>\n","      <td>69</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>72</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>484</td>\n","      <td>498</td>\n","      <td>19.0</td>\n","      <td>5</td>\n","      <td>472.0</td>\n","      <td>315.000000</td>\n","      <td>315.000000</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>339</td>\n","      <td>Mapplethorpe, Robert</td>\n","      <td>Photograph</td>\n","      <td>1</td>\n","      <td>1992</td>\n","      <td>46</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2006</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>OnsiteAndOffsite</td>\n","      <td>0.0</td>\n","      <td>40.712728</td>\n","      <td>-74.006015</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>2</td>\n","      <td>82</td>\n","      <td>516</td>\n","      <td>1461</td>\n","      <td>438</td>\n","      <td>119</td>\n","      <td>1338.0</td>\n","      <td>1295.0</td>\n","      <td>65</td>\n","      <td>1552.0</td>\n","      <td>1022.0</td>\n","      <td>1636.0</td>\n","      <td>1623.0</td>\n","      <td>1522.0</td>\n","      <td>1486.0</td>\n","      <td>1406.0</td>\n","      <td>216</td>\n","      <td>216</td>\n","      <td>569.0</td>\n","      <td>775</td>\n","      <td>577.0</td>\n","      <td>188.000000</td>\n","      <td>188.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           r  ... artist_birthplace_lon\n","count   1665  ...           1665.000000\n","unique  1620  ...            315.000000\n","top      339  ...            -74.006015\n","freq       2  ...            188.000000\n","\n","[4 rows x 23 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"M20fBPB8z08D"},"source":["# mean, std, correlations \r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]}]}